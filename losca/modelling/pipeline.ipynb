{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "# Import stratifiedKFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "def scale_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    for col in data.columns:\n",
    "        if is_numeric_dtype(data[col]):\n",
    "            data[col] = scaler.fit_transform(data[[col]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.566699</td>\n",
       "      <td>-1.518325</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.218544</td>\n",
       "      <td>-1.187601</td>\n",
       "      <td>b</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.870388</td>\n",
       "      <td>-0.856876</td>\n",
       "      <td>c</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.522233</td>\n",
       "      <td>-0.526152</td>\n",
       "      <td>d</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174078</td>\n",
       "      <td>-0.195428</td>\n",
       "      <td>e</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.174078</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>f</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.466021</td>\n",
       "      <td>g</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.870388</td>\n",
       "      <td>0.796745</td>\n",
       "      <td>h</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.218544</td>\n",
       "      <td>1.127469</td>\n",
       "      <td>i</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.566699</td>\n",
       "      <td>1.758852</td>\n",
       "      <td>j</td>\n",
       "      <td>&lt;class 'object'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b  c                 d\n",
       "0 -1.566699 -1.518325  a  <class 'object'>\n",
       "1 -1.218544 -1.187601  b  <class 'object'>\n",
       "2 -0.870388 -0.856876  c  <class 'object'>\n",
       "3 -0.522233 -0.526152  d  <class 'object'>\n",
       "4 -0.174078 -0.195428  e  <class 'object'>\n",
       "5  0.174078  0.135296  f  <class 'object'>\n",
       "6  0.522233  0.466021  g  <class 'object'>\n",
       "7  0.870388  0.796745  h  <class 'object'>\n",
       "8  1.218544  1.127469  i  <class 'object'>\n",
       "9  1.566699  1.758852  j  <class 'object'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "b = [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9, 12.0]\n",
    "c = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "d = [object, object, object, object, object, object, object, object, object, object]\n",
    "data = {'a': a, 'b': b, 'c': c, 'd': d}\n",
    "df = pd.DataFrame(data)\n",
    "df = scale_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(model, X, y):\n",
    "    cv_strat = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_results = cross_validate(model, X, y, cv=cv_strat, scoring=['neg_root_mean_squared_error'], return_train_score=True, return_estimator=True)\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_cv_results(cv_results):\n",
    "    avg_results = {}\n",
    "    print(cv_results.keys())\n",
    "    for key in cv_results.keys():\n",
    "        if key == 'estimator':\n",
    "            continue\n",
    "        avg_results[key] = cv_results[key].mean()\n",
    "    # Get best estimator according to RMSE\n",
    "    best_estimator_index = cv_results['test_neg_root_mean_squared_error'].argmax()\n",
    "    best_estimator = cv_results['estimator'][best_estimator_index]\n",
    "    return avg_results, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_model(df, target, drop_cols=[]):\n",
    "    from lazypredict.supervised import LazyRegressor\n",
    "    X = df.drop(columns=[target] + drop_cols)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "    models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                       index = X.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending=False)\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        feature_importances = pd.DataFrame(model.coef_,\n",
    "                                       index = X.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending=False)\n",
    "    else:\n",
    "        print('Model does not have feature importances')\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152, 9), (152,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from pkl\n",
    "cf = pd.read_pickle('../../data/processed/cf.pkl')\n",
    "# Target is producto_1_cf\n",
    "y = cf['producto_1_cf']\n",
    "# Features are all columns except producto_1_cf\n",
    "X = cf.drop(columns=['producto_1_cf'])\n",
    "# Drop all columns which are not numeric\n",
    "#X = X.select_dtypes(include=['number'])\n",
    "drop_cols = ['producto_2_cf','lote', 'lote_parental_cf','id_bio', 'f_h_inicio_cf' , 'f_h_fin_cf' , 'id_centr']\n",
    "X = X.drop(columns=drop_cols)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   lote                    152 non-null    object             \n",
      " 1   orden_encadenado_cf     152 non-null    int64              \n",
      " 2   lote_parental_cf        152 non-null    object             \n",
      " 3   id_bio                  152 non-null    object             \n",
      " 4   f_h_inicio_cf           152 non-null    datetime64[ns, UTC]\n",
      " 5   f_h_fin_cf              152 non-null    datetime64[ns, UTC]\n",
      " 6   vol_ino_util_cf         147 non-null    float64            \n",
      " 7   turb_inicio_cultivo_cf  152 non-null    float64            \n",
      " 8   turb_fin_cultivo_cf     152 non-null    float64            \n",
      " 9   viab_final_cultivo_cf   152 non-null    float64            \n",
      " 10  id_centr                152 non-null    object             \n",
      " 11  centr_1_turb_cf         148 non-null    float64            \n",
      " 12  centr_2_turb_cf         143 non-null    float64            \n",
      " 13  producto_1_cf           152 non-null    float64            \n",
      " 14  producto_2_cf           152 non-null    float64            \n",
      " 15  dur_cf                  152 non-null    int64              \n",
      " 16  turbidez_diff_cf        152 non-null    float64            \n",
      "dtypes: datetime64[ns, UTC](2), float64(9), int64(2), object(4)\n",
      "memory usage: 20.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'estimator', 'test_neg_root_mean_squared_error', 'train_neg_root_mean_squared_error'])\n",
      "test average RMSE: -281.71982480810885\n",
      "train average RMSE: -108.9460756680335\n",
      "best_estimator test RMSE: -201.67850881638307\n",
      "                        importance\n",
      "turbidez_diff_cf              0.22\n",
      "turb_fin_cultivo_cf           0.15\n",
      "centr_2_turb_cf               0.15\n",
      "centr_1_turb_cf               0.11\n",
      "viab_final_cultivo_cf         0.10\n",
      "dur_cf                        0.09\n",
      "vol_ino_util_cf               0.08\n",
      "turb_inicio_cultivo_cf        0.08\n",
      "orden_encadenado_cf           0.01\n"
     ]
    }
   ],
   "source": [
    "# Perform cross validation\n",
    "# Scale\n",
    "X = scale_data(X)\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "cv_results = cross_validate_model(model, X, y)\n",
    "avg_results, best_estimator = average_cv_results(cv_results)\n",
    "print('test average RMSE:', avg_results['test_neg_root_mean_squared_error'])\n",
    "print('train average RMSE:', avg_results['train_neg_root_mean_squared_error'])\n",
    "print('best_estimator test RMSE:', cv_results['test_neg_root_mean_squared_error'].max())\n",
    "print(feature_importance(best_estimator, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 98.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 121, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 1672.990337\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.42</td>\n",
       "      <td>196.34</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>201.66</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.35</td>\n",
       "      <td>207.86</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.34</td>\n",
       "      <td>210.86</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>212.91</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>213.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>213.76</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>213.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>214.17</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>214.17</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>214.33</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>214.79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>214.79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>215.79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>216.46</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>217.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>218.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>218.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>218.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>218.24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>218.26</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>218.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>218.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>219.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>219.18</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>221.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>221.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>224.36</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>225.29</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>233.84</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>239.89</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>266.12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>268.46</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>268.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>270.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>270.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>-1.27</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>326.53</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-5.69</td>\n",
       "      <td>-3.68</td>\n",
       "      <td>560.09</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-8.40</td>\n",
       "      <td>-5.58</td>\n",
       "      <td>663.64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-47.16</td>\n",
       "      <td>-32.71</td>\n",
       "      <td>1502.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-54.02</td>\n",
       "      <td>-37.51</td>\n",
       "      <td>1605.92</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-60.64</td>\n",
       "      <td>-42.15</td>\n",
       "      <td>1699.82</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared  R-Squared    RMSE  \\\n",
       "Model                                                                  \n",
       "ExtraTreesRegressor                          0.18       0.42  196.34   \n",
       "RandomForestRegressor                        0.13       0.39  201.66   \n",
       "BaggingRegressor                             0.08       0.35  207.86   \n",
       "AdaBoostRegressor                            0.05       0.34  210.86   \n",
       "LassoLarsIC                                  0.03       0.32  212.91   \n",
       "ElasticNet                                   0.03       0.32  213.67   \n",
       "ElasticNetCV                                 0.03       0.32  213.76   \n",
       "BayesianRidge                                0.02       0.32  213.81   \n",
       "LarsCV                                       0.02       0.31  214.17   \n",
       "LassoLarsCV                                  0.02       0.31  214.17   \n",
       "LassoCV                                      0.02       0.31  214.33   \n",
       "LinearRegression                             0.02       0.31  214.79   \n",
       "TransformedTargetRegressor                   0.02       0.31  214.79   \n",
       "TweedieRegressor                             0.01       0.30  215.79   \n",
       "RidgeCV                                      0.00       0.30  216.46   \n",
       "GammaRegressor                              -0.01       0.29  217.75   \n",
       "PassiveAggressiveRegressor                  -0.01       0.29  218.00   \n",
       "Ridge                                       -0.01       0.29  218.01   \n",
       "Lars                                        -0.02       0.29  218.22   \n",
       "LassoLars                                   -0.02       0.29  218.24   \n",
       "Lasso                                       -0.02       0.29  218.26   \n",
       "PoissonRegressor                            -0.02       0.29  218.30   \n",
       "SGDRegressor                                -0.02       0.28  218.85   \n",
       "GradientBoostingRegressor                   -0.02       0.28  219.02   \n",
       "HuberRegressor                              -0.02       0.28  219.18   \n",
       "OrthogonalMatchingPursuit                   -0.05       0.26  221.85   \n",
       "OrthogonalMatchingPursuitCV                 -0.05       0.26  221.85   \n",
       "LGBMRegressor                               -0.07       0.25  224.36   \n",
       "KNeighborsRegressor                         -0.08       0.24  225.29   \n",
       "HistGradientBoostingRegressor               -0.17       0.18  233.84   \n",
       "XGBRegressor                                -0.23       0.14  239.89   \n",
       "NuSVR                                       -0.51      -0.06  266.12   \n",
       "DecisionTreeRegressor                       -0.54      -0.08  268.46   \n",
       "DummyRegressor                              -0.54      -0.08  268.59   \n",
       "SVR                                         -0.56      -0.09  270.16   \n",
       "QuantileRegressor                           -0.57      -0.10  270.97   \n",
       "ExtraTreeRegressor                          -1.27      -0.59  326.53   \n",
       "RANSACRegressor                             -5.69      -3.68  560.09   \n",
       "GaussianProcessRegressor                    -8.40      -5.58  663.64   \n",
       "LinearSVR                                  -47.16     -32.71 1502.49   \n",
       "MLPRegressor                               -54.02     -37.51 1605.92   \n",
       "KernelRidge                                -60.64     -42.15 1699.82   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "ExtraTreesRegressor                  0.04  \n",
       "RandomForestRegressor                0.05  \n",
       "BaggingRegressor                     0.01  \n",
       "AdaBoostRegressor                    0.03  \n",
       "LassoLarsIC                          0.00  \n",
       "ElasticNet                           0.00  \n",
       "ElasticNetCV                         0.02  \n",
       "BayesianRidge                        0.00  \n",
       "LarsCV                               0.01  \n",
       "LassoLarsCV                          0.01  \n",
       "LassoCV                              0.02  \n",
       "LinearRegression                     0.00  \n",
       "TransformedTargetRegressor           0.00  \n",
       "TweedieRegressor                     0.00  \n",
       "RidgeCV                              0.00  \n",
       "GammaRegressor                       0.00  \n",
       "PassiveAggressiveRegressor           0.00  \n",
       "Ridge                                0.00  \n",
       "Lars                                 0.00  \n",
       "LassoLars                            0.00  \n",
       "Lasso                                0.00  \n",
       "PoissonRegressor                     0.00  \n",
       "SGDRegressor                         0.00  \n",
       "GradientBoostingRegressor            0.03  \n",
       "HuberRegressor                       0.01  \n",
       "OrthogonalMatchingPursuit            0.00  \n",
       "OrthogonalMatchingPursuitCV          0.00  \n",
       "LGBMRegressor                        0.01  \n",
       "KNeighborsRegressor                  0.00  \n",
       "HistGradientBoostingRegressor        0.03  \n",
       "XGBRegressor                         0.02  \n",
       "NuSVR                                0.00  \n",
       "DecisionTreeRegressor                0.00  \n",
       "DummyRegressor                       0.00  \n",
       "SVR                                  0.00  \n",
       "QuantileRegressor                    0.00  \n",
       "ExtraTreeRegressor                   0.00  \n",
       "RANSACRegressor                      0.03  \n",
       "GaussianProcessRegressor             0.00  \n",
       "LinearSVR                            0.00  \n",
       "MLPRegressor                         0.03  \n",
       "KernelRidge                          0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lazy_model(cf, 'producto_1_cf', drop_cols=drop_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "losca-RpR7jZx6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
